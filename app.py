import streamlit as st
import asyncio
import aiohttp
import time
import random
from fake_useragent import UserAgent
from bs4 import BeautifulSoup
import os
from dotenv import load_dotenv
import pandas as pd
import plotly.graph_objs as go
from textblob import TextBlob
import json
from datetime import datetime
import altair as alt
import re
from collections import Counter
import nltk
import chardet
from typing import Dict, List, Tuple, Any, Optional

nltk.download('punkt')

load_dotenv()

# å®šæ•°ã®å®šç¾©
API_ENDPOINTS: Dict[str, str] = {
    "CLAUDE": "https://api.anthropic.com/v1/messages",
}
RETRY_ATTEMPTS: int = 5
MAX_CONCURRENT_REQUESTS: int = 3
BASE_DELAY: int = 2
MAX_RETRIES: int = 15
MAX_BACKOFF_DELAY: int = 60
WEBPAGE_TIMEOUT: int = 30
KEYWORDS_FILE: str = "keywords.json"

TAVILY_API_KEY: Optional[str] = os.environ.get("TAVILY_API_KEY")
CLAUDE_API_KEY: Optional[str] = os.environ.get("CLAUDE_API_KEY")

def load_keywords() -> Dict[str, List[str]]:
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€

    Returns:
        Dict[str, List[str]]: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸
    """
    if os.path.exists(KEYWORDS_FILE):
        with open(KEYWORDS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_keywords(keywords: Dict[str, List[str]]) -> None:
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹

    Args:
        keywords (Dict[str, List[str]]): ä¿å­˜ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸
    """
    with open(KEYWORDS_FILE, 'w', encoding='utf-8') as f:
        json.dump(keywords, f, ensure_ascii=False, indent=2)

KEYWORDS: Dict[str, List[str]] = load_keywords()

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'processing' not in st.session_state:
    st.session_state.processing = False
if 'result' not in st.session_state:
    st.session_state.result = None
if 'api_status' not in st.session_state:
    st.session_state.api_status = ""
if 'selected_result' not in st.session_state:
    st.session_state.selected_result = None

def calculate_risk_score(text: str) -> float:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹

    Args:
        text (str): åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        float: è¨ˆç®—ã•ã‚ŒãŸãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢
    """
    blob = TextBlob(text)
    sentiment = blob.sentiment.polarity
    subjectivity = blob.sentiment.subjectivity
    
    sentiment_score = (1 - sentiment) * 50
    subjectivity_score = subjectivity * 50
    risk_score = (sentiment_score + subjectivity_score) / 2
    
    print(f"Text: {text[:100]}...")
    print(f"Sentiment: {sentiment}, Subjectivity: {subjectivity}")
    print(f"Calculated Risk Score: {risk_score}")
    
    return risk_score

async def get_webpage_content(session: aiohttp.ClientSession, url: str) -> str:
    """
    æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—ã™ã‚‹

    Args:
        session (aiohttp.ClientSession): aiohttp ã‚»ãƒƒã‚·ãƒ§ãƒ³
        url (str): å–å¾—å¯¾è±¡ã®URL

    Returns:
        str: å–å¾—ã•ã‚ŒãŸã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã®å†…å®¹ï¼ˆHTMLã‚¿ã‚°é™¤å»æ¸ˆã¿ï¼‰
    """
    try:
        ua = UserAgent()
        headers = {'User-Agent': ua.random}
        async with session.get(url, headers=headers, timeout=WEBPAGE_TIMEOUT) as response:
            response.raise_for_status()
            content = await response.read()
            encoding = chardet.detect(content)['encoding']
            if encoding is None:
                encoding = 'utf-8'
            html = content.decode(encoding, errors='replace')
            return strip_html_tags(html)
    except asyncio.TimeoutError:
        st.warning(f"Timeout error when fetching {url}")
        return ""
    except aiohttp.ClientError as e:
        st.error(f"Error fetching webpage {url}: {e}")
        return ""
    except UnicodeDecodeError as e:
        st.error(f"Error decoding webpage content from {url}: {e}")
        return ""

def strip_html_tags(html: str) -> str:
    """
    HTMLã‚¿ã‚°ã‚’é™¤å»ã™ã‚‹

    Args:
        html (str): HTMLã‚¿ã‚°ã‚’å«ã‚€æ–‡å­—åˆ—

    Returns:
        str: HTMLã‚¿ã‚°ã‚’é™¤å»ã—ãŸæ–‡å­—åˆ—
    """
    soup = BeautifulSoup(html, "html.parser")
    return soup.get_text()

async def call_claude_api_with_advanced_backoff(session: aiohttp.ClientSession, url: str, payload: Dict[str, Any], headers: Dict[str, str]) -> Dict[str, Any]:
    """
    é«˜åº¦ãªãƒãƒƒã‚¯ã‚ªãƒ•æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¦Claude APIã‚’å‘¼ã³å‡ºã™

    Args:
        session (aiohttp.ClientSession): aiohttp ã‚»ãƒƒã‚·ãƒ§ãƒ³
        url (str): APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURL
        payload (Dict[str, Any]): APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰
        headers (Dict[str, str]): APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼

    Returns:
        Dict[str, Any]: APIãƒ¬ã‚¹ãƒãƒ³ã‚¹
    """
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
    
    async def api_call():
        async with semaphore:
            for attempt in range(MAX_RETRIES):
                try:
                    async with session.post(url, json=payload, headers=headers) as response:
                        if response.status in [429, 529]:
                            delay = min(BASE_DELAY * (2 ** attempt) + random.uniform(0, 1), MAX_BACKOFF_DELAY)
                            st.session_state.api_status = f"API overloaded or rate limited. Retrying in {delay:.2f} seconds..."
                            await asyncio.sleep(delay)
                            continue
                        response.raise_for_status()
                        st.session_state.api_status = ""
                        return await response.json()
                except aiohttp.ClientResponseError as e:
                    if e.status == 529:
                        delay = min(BASE_DELAY * (2 ** attempt) + random.uniform(0, 1), MAX_BACKOFF_DELAY)
                        st.session_state.api_status = f"API overloaded. Retrying in {delay:.2f} seconds..."
                        await asyncio.sleep(delay)
                    elif attempt == MAX_RETRIES - 1:
                        st.session_state.api_status = "Max retries reached. API call failed."
                        raise
                    else:
                        delay = min(BASE_DELAY * (2 ** attempt) + random.uniform(0, 1), MAX_BACKOFF_DELAY)
                        st.session_state.api_status = f"API call failed. Retrying in {delay:.2f} seconds... Error: {e}"
                        await asyncio.sleep(delay)
                except aiohttp.ClientError as e:
                    if attempt == MAX_RETRIES - 1:
                        st.session_state.api_status = "Max retries reached. API call failed."
                        raise
                    delay = min(BASE_DELAY * (2 ** attempt) + random.uniform(0, 1), MAX_BACKOFF_DELAY)
                    st.session_state.api_status = f"API call failed. Retrying in {delay:.2f} seconds... Error: {e}"
                    await asyncio.sleep(delay)
            st.session_state.api_status = "Max retries reached. API call failed."
            raise Exception("Max retries reached")

    return await api_call()

async def collect_risk_info(session: aiohttp.ClientSession, talent_name: str, risk_word: str, max_results: int, api_key: str) -> Optional[Dict[str, Any]]:
    """
    Tavily APIã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¹ã‚¯æƒ…å ±ã‚’åé›†ã™ã‚‹

    Args:
        session (aiohttp.ClientSession): aiohttp ã‚»ãƒƒã‚·ãƒ§ãƒ³
        talent_name (str): ã‚¿ãƒ¬ãƒ³ãƒˆå
        risk_word (str): ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰
        max_results (int): å–å¾—ã™ã‚‹æœ€å¤§çµæœæ•°
        api_key (str): Tavily API ã‚­ãƒ¼

    Returns:
        Optional[Dict[str, Any]]: åé›†ã•ã‚ŒãŸãƒªã‚¹ã‚¯æƒ…å ±ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
    """
    url = "https://api.tavily.com/search"
    query = f"{talent_name} {risk_word}"
    payload = {
        "api_key": api_key,
        "query": query,
        "search_depth": "advanced",
        "include_answer": True,
        "include_images": False,
        "include_raw_content": False,
        "max_results": max_results,
        "include_domains": [],
        "exclude_domains": []
    }
    try:
        async with session.post(url, json=payload) as response:
            response.raise_for_status()
            return await response.json()
    except aiohttp.ClientError as e:
        st.error(f"Error with Tavily API: {e}")
        return None

async def expand_keywords(session: aiohttp.ClientSession, api_key: str, risk_word: str) -> List[str]:
    """
    Claude APIã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰ã«é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹

    Args:
        session (aiohttp.ClientSession): aiohttp ã‚»ãƒƒã‚·ãƒ§ãƒ³
        api_key (str): Claude API ã‚­ãƒ¼
        risk_word (str): æ‹¡å¼µã™ã‚‹ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰

    Returns:
        List[str]: ç”Ÿæˆã•ã‚ŒãŸé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
    """
    url = API_ENDPOINTS["CLAUDE"]
    prompt = f"'{risk_word}'ã«é–¢é€£ã™ã‚‹å˜èªã‚’10å€‹ã€æ—¥æœ¬èªã§æŒ™ã’ã¦ãã ã•ã„ã€‚ã“ã‚Œã‚‰ã®å˜èªã¯ã€ã‚¿ãƒ¬ãƒ³ãƒˆã®ç‚ä¸Šãƒªã‚¹ã‚¯ã‚’è©•ä¾¡ã™ã‚‹éš›ã«å½¹ç«‹ã¤ã‚‚ã®ã¨ã—ã¾ã™ã€‚å˜èªã®ã¿ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ãƒªã‚¹ãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
    
    payload = {
        "model": "claude-3-opus-20240229",
        "max_tokens": 150,
        "temperature": 0.5,
        "messages": [
            {"role": "user", "content": prompt}
        ],
    }
    headers = {
        "Content-Type": "application/json",
        "X-API-Key": api_key,
        "anthropic-version": "2023-06-01"
    }
    
    try:
        response_data = await call_claude_api_with_advanced_backoff(session, url, payload, headers)
        if 'content' in response_data:
            related_words = response_data['content'][0]['text'].split(',')
            return [word.strip() for word in related_words]
        else:
            st.error(f"Unexpected response format: {response_data}")
            return []
    except Exception as e:
        st.error(f"Failed to expand keywords: {e}")
        return []

def update_keywords(risk_word: str, related_words: List[str]) -> None:
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸ã‚’æ›´æ–°ã—ã€æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã¨é–¢é€£ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã™ã‚‹

    Args:
        risk_word (str): æ–°ã—ã„ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ†ã‚´ãƒªï¼‰
        related_words (List[str]): é–¢é€£ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
    """
    global KEYWORDS
    if risk_word not in KEYWORDS:
        KEYWORDS[risk_word] = related_words
        save_keywords(KEYWORDS)
        st.info(f"Added new category '{risk_word}' to KEYWORDS with related words: {', '.join(related_words)}")

async def calculate_advanced_risk_score(session: aiohttp.ClientSession, api_key: str, text: str, risk_category: str) -> Tuple[float, Dict[str, float]]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã®é«˜åº¦ãªãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹

    Args:
        session (aiohttp.ClientSession): aiohttp ã‚»ãƒƒã‚·ãƒ§ãƒ³
        api_key (str): Claude API ã‚­ãƒ¼
        text (str): åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
        risk_category (str): ãƒªã‚¹ã‚¯ã‚«ãƒ†ã‚´ãƒª

    Returns:
        Tuple[float, Dict[str, float]]: æ­£è¦åŒ–ã•ã‚ŒãŸãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã¨ã‚¹ã‚³ã‚¢ã®è©³ç´°
    """
    global KEYWORDS
    if risk_category not in KEYWORDS:
        related_words = await expand_keywords(session, api_key, risk_category)
        update_keywords(risk_category, related_words)
    
    blob = TextBlob(text)
    sentiment = blob.sentiment.polarity
    subjectivity = blob.sentiment.subjectivity

    word_counts = Counter(word for word in text.lower().split() if word in KEYWORDS[risk_category])
    keyword_score = sum(word_counts.values()) * 10

    numbers = re.findall(r'\d+', text)
    number_score = sum(int(num) for num in numbers if int(num) > 10) * 0.5

    context_phrases = [
        "è¬ç½ª", "æ‰¹åˆ¤", "å•é¡Œ", "ç‚ä¸Š", "é€®æ•", "ç–‘æƒ‘", "ã‚¹ã‚­ãƒ£ãƒ³ãƒ€ãƒ«", 
        "é™æ¿", "å¥‘ç´„è§£é™¤", "å¼•é€€", "æ´»å‹•ä¼‘æ­¢", "è¬¹æ…", 
        "ä¸å€«", "æµ®æ°—", "ã‚´ã‚·ãƒƒãƒ—", "é›¢å©š", "ç ´å±€", "ä¸ç¥¥äº‹", 
        "é€®æ•çŠ¶", "æ‘˜ç™º", "èµ·è¨´", "æ›¸é¡é€æ¤œ", "å®¶å®…æœç´¢", 
        "è–¬ç‰©", "é£²é…’é‹è»¢", "æš´è¡Œ", "çªƒç›—", "è„±ç¨", 
        "ãƒ‘ãƒ¯ãƒãƒ©", "ã‚»ã‚¯ãƒãƒ©", "ãƒ¢ãƒ©ãƒãƒ©", "ã„ã˜ã‚", 
        "è©æ¬º", "æ¨ªé ˜", "é•æ³•", "çŠ¯ç½ª", "è£åˆ¤", 
        "æš´åŠ›å›£", "åç¤¾ä¼šçš„å‹¢åŠ›", "é•æ³•è³­åš", 
        "æœªæˆå¹´", "æ·«è¡Œ", "ã‚ã„ã›ã¤", "å…ç«¥ãƒãƒ«ãƒ", 
        "æš´è¨€", "å·®åˆ¥", "ç‚ä¸Šå•†æ³•", "SNSç‚ä¸Š"
    ]
    context_score = sum(10 for phrase in context_phrases if phrase in text)

    complexity_score = len(text.split()) * 0.1
    sentiment_score = (1 - sentiment) * 25
    subjectivity_score = subjectivity * 25

    total_score = (
        keyword_score + 
        number_score + 
        context_score + 
        complexity_score + 
        sentiment_score + 
        subjectivity_score
    )

    normalized_score = min(100, max(0, total_score))

    return normalized_score, {
        "keyword_score": keyword_score,
        "number_score": number_score,
        "context_score": context_score,
        "complexity_score": complexity_score,
        "sentiment_score": sentiment_score,
        "subjectivity_score": subjectivity_score
    }

async def summarize_risk_content(session: aiohttp.ClientSession, content: str, risk_word: str, max_length: int, model: str, api_key: str) -> str:
    """
    ãƒªã‚¹ã‚¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¦ç´„ã™ã‚‹

    Args:
        session (aiohttp.ClientSession): aiohttp ã‚»ãƒƒã‚·ãƒ§ãƒ³
        content (str): è¦ç´„ã™ã‚‹å†…å®¹
        risk_word (str): ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰
        max_length (int): è¦ç´„ã®æœ€å¤§é•·
        model (str): ä½¿ç”¨ã™ã‚‹Claudeãƒ¢ãƒ‡ãƒ«
        api_key (str): Claude API ã‚­ãƒ¼

    Returns:
        str: è¦ç´„ã•ã‚ŒãŸãƒªã‚¹ã‚¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    """
    url = API_ENDPOINTS["CLAUDE"]
    prompt = f"ä»¥ä¸‹ã®æ–‡ç« ã‹ã‚‰{risk_word}ã«é–¢é€£ã™ã‚‹å†…å®¹ã‚’{max_length}æ–‡å­—ç¨‹åº¦ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚ç‰¹ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ãªå†…å®¹ã‚„æ½œåœ¨çš„ãªãƒªã‚¹ã‚¯ã«æ³¨ç›®ã—ã¦ãã ã•ã„ã€‚é–¢é€£ã™ã‚‹å†…å®¹ãŒãªã„å ´åˆã¯ã€Œé–¢é€£æƒ…å ±ãªã—ã€ã¨è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚\n\n{content}"
    payload = {
        "model": model,
        "max_tokens": min(max_length, 4096),
        "temperature": 0.5,
        "messages": [
            {"role": "user", "content": prompt}
        ],
    }
    headers = {
        "Content-Type": "application/json",
        "X-API-Key": api_key,
        "anthropic-version": "2023-06-01"
    }
    
    try:
        response_data = await call_claude_api_with_advanced_backoff(session, url, payload, headers)
        if 'content' in response_data:
            return response_data['content'][0]['text']
        else:
            st.error(f"Unexpected response format: {response_data}")
            return ""
    except Exception as e:
        st.error(f"Failed to summarize content: {e}")
        return ""

async def generate_risk_report(session: aiohttp.ClientSession, talent_name: str, risk_summaries: Dict[str, List[str]], model: str, api_key: str, articles: List[Dict[str, Any]]) -> str:
    """
    ã‚¿ãƒ¬ãƒ³ãƒˆã®ãƒªã‚¹ã‚¯ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹

    Args:
        session (aiohttp.ClientSession): aiohttp ã‚»ãƒƒã‚·ãƒ§ãƒ³
        talent_name (str): ã‚¿ãƒ¬ãƒ³ãƒˆå
        risk_summaries (Dict[str, List[str]]): ãƒªã‚¹ã‚¯è¦ç´„
        model (str): ä½¿ç”¨ã™ã‚‹Claudeãƒ¢ãƒ‡ãƒ«
        api_key (str): Claude API ã‚­ãƒ¼
        articles (List[Dict[str, Any]]): åé›†ã•ã‚ŒãŸè¨˜äº‹æƒ…å ±

    Returns:
        str: ç”Ÿæˆã•ã‚ŒãŸãƒªã‚¹ã‚¯ãƒ¬ãƒãƒ¼ãƒˆ
    """
    url = API_ENDPOINTS["CLAUDE"]
    summaries_text = "\n\n".join([f"{word}:\n{summary}" for word, summary in risk_summaries.items()])
    articles_info = "\n".join([f"[{a['index']}] {a['title']} - {a['url']} (Risk: {a['risk_word']})" for a in articles])
    prompt = f"""ä»¥ä¸‹ã¯{talent_name}ã«é–¢ã™ã‚‹å„ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰ã®è¦ç´„ã§ã™ã€‚ã“ã‚Œã‚‰ã®æƒ…å ±ã‚’åŸºã«ã€{talent_name}ã®ç‚ä¸Šãƒªã‚¹ã‚¯ã‚’è©•ä¾¡ã—ã€500æ–‡å­—ç¨‹åº¦ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒ¬ãƒãƒ¼ãƒˆã«ã¯å…¨ä½“çš„ãªãƒªã‚¹ã‚¯è©•ä¾¡ã¨ã€ç‰¹ã«æ³¨æ„ã™ã¹ãç‚¹ã‚’å«ã‚ã¦ãã ã•ã„ã€‚ã¾ãŸã€é‡è¦ãªæƒ…å ±ã®å‡ºå…¸ã¨ã—ã¦ã€é©åˆ‡ãªè¨˜äº‹ç•ªå·ï¼ˆ[index]ã®å½¢å¼ï¼‰ã‚’æ‹¬å¼§æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚

è¦ç´„:
{summaries_text}

è¨˜äº‹ä¸€è¦§:
{articles_info}
"""
    
    payload = {
        "model": model,
        "max_tokens": 4096,
        "temperature": 0.5,
        "messages": [
            {"role": "user", "content": prompt}
        ],
    }
    headers = {
        "Content-Type": "application/json",
        "X-API-Key": api_key,
        "anthropic-version": "2023-06-01"
    }
    
    try:
        response_data = await call_claude_api_with_advanced_backoff(session, url, payload, headers)
        if 'content' in response_data:
            return response_data['content'][0]['text']
        else:
            st.error(f"Unexpected response format: {response_data}")
            return ""
    except Exception as e:
        st.error(f"Failed to generate risk report: {e}")
        return ""

async def process_talent_risks(session: aiohttp.ClientSession, TAVILY_API_KEY: str, CLAUDE_API_KEY: str, talent_name: str, max_results: int, summarization_length: int, claude_model: str, risk_words: List[str]) -> Dict[str, Any]:
    """
    ã‚¿ãƒ¬ãƒ³ãƒˆã®ãƒªã‚¹ã‚¯æƒ…å ±ã‚’å‡¦ç†ã™ã‚‹

    Args:
        session (aiohttp.ClientSession): aiohttp ã‚»ãƒƒã‚·ãƒ§ãƒ³
        TAVILY_API_KEY (str): Tavily API ã‚­ãƒ¼
        CLAUDE_API_KEY (str): Claude API ã‚­ãƒ¼
        talent_name (str): ã‚¿ãƒ¬ãƒ³ãƒˆå
        max_results (int): ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰ã”ã¨ã®æœ€å¤§çµæœæ•°
        summarization_length (int): è¦ç´„ã®é•·ã•
        claude_model (str): ä½¿ç”¨ã™ã‚‹Claudeãƒ¢ãƒ‡ãƒ«
        risk_words (List[str]): ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ

    Returns:
        Dict[str, Any]: å‡¦ç†çµæœ
    """
    risk_summaries = {}
    all_articles = []
    article_counter = 1

    progress_bar = st.progress(0)
    status_text = st.empty()

    for i, risk_word in enumerate(risk_words):
        status_text.text(f"Analyzing risk: {risk_word}")
        if risk_word not in KEYWORDS:
            await expand_keywords(session, CLAUDE_API_KEY, risk_word)
        
        risk_info = await collect_risk_info(session, talent_name, risk_word, max_results, TAVILY_API_KEY)
        if risk_info:
            for j, result in enumerate(risk_info["results"][:max_results]):
                article = {
                    "index": article_counter,
                    "title": result["title"],
                    "url": result["url"],
                    "risk_word": risk_word
                }
                all_articles.append(article)
                article_counter += 1

                status_text.text(f"Processing article {article['index']}: {article['title']}")
                webpage_content = await get_webpage_content(session, article["url"])
                if webpage_content:
                    summary = await summarize_risk_content(session, webpage_content, risk_word, summarization_length, claude_model, CLAUDE_API_KEY)
                    if summary:
                        article["summary"] = summary
                        article["risk_score"], article["score_details"] = await calculate_advanced_risk_score(session, CLAUDE_API_KEY, summary, risk_word)
                        if risk_word not in risk_summaries:
                            risk_summaries[risk_word] = []
                        risk_summaries[risk_word].append(f"[{article['index']}] {summary} (Risk Score: {article['risk_score']:.2f})")
                    else:
                        st.warning(f"Failed to summarize article {article['index']}")
                else:
                    st.warning(f"Failed to fetch content for article {article['index']}")

        progress_bar.progress((i + 1) / len(risk_words))

    status_text.text("Generating final report...")
    risk_report = await generate_risk_report(session, talent_name, risk_summaries, claude_model, CLAUDE_API_KEY, all_articles)
    
    return {
        "talent_name": talent_name,
        "risk_summaries": risk_summaries,
        "risk_report": risk_report,
        "articles": all_articles
    }

def save_result(result: Dict[str, Any]) -> None:
    """
    çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ã™ã‚‹

    Args:
        result (Dict[str, Any]): ä¿å­˜ã™ã‚‹çµæœ
    """
    if "saved_results" not in st.session_state:
        st.session_state.saved_results = []
    st.session_state.saved_results.append({
        "timestamp": datetime.now().isoformat(),
        "talent_name": result["talent_name"],
        "risk_report": result["risk_report"],
        "articles": result["articles"],
        "risk_summaries": result["risk_summaries"]
    })

def display_risk_visualization(result: Dict[str, Any]) -> None:
    """
    ãƒªã‚¹ã‚¯å¯è¦–åŒ–ã‚’è¡¨ç¤ºã™ã‚‹

    Args:
        result (Dict[str, Any]): è¡¨ç¤ºã™ã‚‹çµæœ
    """
    st.subheader("ç‚ä¸Šãƒªã‚¹ã‚¯å¯è¦–åŒ–")

    risk_scores = [article['risk_score'] for article in result['articles'] if 'risk_score' in article]
    if risk_scores:
        avg_risk_score = sum(risk_scores) / len(risk_scores)
        fig = go.Figure(go.Indicator(
            mode = "gauge+number",
            value = avg_risk_score,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "å¹³å‡ç‚ä¸Šãƒªã‚¹ã‚¯åº¦"},
            gauge = {
                'axis': {'range': [0, 100]},
                'bar': {'color': "darkred"},
                'steps' : [
                    {'range': [0, 33], 'color': "green"},
                    {'range': [33, 66], 'color': "yellow"},
                    {'range': [66, 100], 'color': "red"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': avg_risk_score
                }
            }
        ))
        st.plotly_chart(fig)
    
    risk_word_scores = {}
    for article in result['articles']:
        if 'risk_score' in article:
            if article['risk_word'] not in risk_word_scores:
                risk_word_scores[article['risk_word']] = []
            risk_word_scores[article['risk_word']].append(article['risk_score'])
    
    if risk_word_scores:
        avg_risk_word_scores = {word: sum(scores) / len(scores) for word, scores in risk_word_scores.items()}
        chart_data = pd.DataFrame({
            'ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰': list(avg_risk_word_scores.keys()),
            'ã‚¹ã‚³ã‚¢': list(avg_risk_word_scores.values())
        })
        
        st.write("ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰åˆ¥å¹³å‡ã‚¹ã‚³ã‚¢:")
        st.write(chart_data)
        
        chart = alt.Chart(chart_data).mark_bar().encode(
            x='ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰',
            y='ã‚¹ã‚³ã‚¢',
            color=alt.Color('ã‚¹ã‚³ã‚¢:Q', scale=alt.Scale(domain=[0, 33, 66, 100], range=['green', 'yellow', 'orange', 'red']))
        ).properties(
            title='ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰åˆ¥å¹³å‡ã‚¹ã‚³ã‚¢'
        )
        
        st.altair_chart(chart, use_container_width=True)

def display_result(result: Dict[str, Any]) -> None:
    """
    çµæœã‚’è¡¨ç¤ºã™ã‚‹

    Args:
        result (Dict[str, Any]): è¡¨ç¤ºã™ã‚‹çµæœ
    """
    if result:
        st.subheader("ç·åˆãƒªã‚¹ã‚¯è©•ä¾¡")
        st.write(result['risk_report'])
        
        display_risk_visualization(result)
        
        st.subheader("ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰åˆ¥è¦ç´„")
        for risk_word, summaries in result['risk_summaries'].items():
            with st.expander(f"{risk_word}"):
                st.write("\n".join(summaries))
        
        st.subheader("å‚ç…§è¨˜äº‹ä¸€è¦§")
        for article in result['articles']:
            if 'risk_score' in article:
                st.write(f"[{article['index']}] {article['title']} - {article['url']} (Risk: {article['risk_word']}, Score: {article['risk_score']:.2f})")
            else:
                st.write(f"[{article['index']}] {article['title']} - {article['url']} (Risk: {article['risk_word']}, Score: N/A)")
        
        report_json = json.dumps(result, ensure_ascii=False, indent=2)
        st.download_button(
            label="ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=report_json,
            file_name=f"{result['talent_name']}_risk_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )

async def main_async() -> None:
    """
    éåŒæœŸãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    st.title("ğŸ”¥ ã‚¿ãƒ¬ãƒ³ãƒˆç‚ä¸Šãƒªã‚¹ã‚¯è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ Î²ç‰ˆ")
    st.text("è¨­å®šã®ã‚¿ãƒ¬ãƒ³ãƒˆåã«åå‰ã‚’å…¥åŠ›ã—ã¦ã€Œãƒ¬ãƒãƒ¼ãƒˆä½œæˆã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™")
    st.text("ã€Œã‚¿ãƒ¬ãƒ³ãƒˆåã€€å„ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰ã€ã§WEBä¸Šã‚’æ¤œç´¢â–¶ãƒ’ãƒƒãƒˆã—ãŸè¨˜äº‹ã‚’AIã§è¦ç´„â–¶è¦ç´„ã—ãŸè¨˜äº‹ã‚’ãƒ™ãƒ¼ã‚¹ã«ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ")
    st.text("ã‚¹ã‚³ã‚¢ã¯è¨˜äº‹å†…ã®ãƒã‚¬ãƒ†ã‚£ãƒ–ãªè¡¨ç¾ãªã©ã‹ã‚‰ç®—å‡º")
    st.sidebar.title("è¨­å®š")

    api_status_placeholder = st.empty()

    talent_name = st.sidebar.text_input("ã‚¿ãƒ¬ãƒ³ãƒˆå", key="talent_name")
    max_results = st.sidebar.slider("ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰ã”ã¨ã®å–å¾—è¨˜äº‹æ•°", 1, 10, 5, key="max_results")
    summarization_length = st.sidebar.slider("è¦ç´„ã™ã‚‹éš›ã®æ–‡å­—æ•°", 100, 500, 350, key="summarization_length")
    claude_model = st.sidebar.selectbox("ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", ["claude-3-opus-20240229", "claude-3-haiku-20240307", "claude-3-sonnet-20240229"], index=1, key="claude_model")

    default_risk_words = "æ”¿æ²»çš„ç™ºè¨€\näº‹ä»¶\nè–¬ç‰©\nåç¤¾\nç†±æ„›\nä¸å€«\nç‚ä¸Š\nå®—æ•™"
    risk_words_input = st.sidebar.text_area("ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰ (1è¡Œã«1ã¤)", value=default_risk_words, height=200, key="risk_words")
    risk_words = [word.strip() for word in risk_words_input.split('\n') if word.strip()]

    if st.sidebar.button("ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"):
        if not TAVILY_API_KEY:
            st.error("Tavily API key is required.")
        elif not talent_name.strip():
            st.error("ã‚¿ãƒ¬ãƒ³ãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif not CLAUDE_API_KEY:
            st.error("Claude API key is required.")
        elif not risk_words:
            st.error("å°‘ãªãã¨ã‚‚1ã¤ã®ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.session_state.processing = True
            async with aiohttp.ClientSession() as session:
                with st.spinner("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­..."):
                    api_status_placeholder.text(st.session_state.api_status)
                    try:
                        result = await process_talent_risks(
                            session, 
                            TAVILY_API_KEY, 
                            CLAUDE_API_KEY, 
                            talent_name, 
                            max_results, 
                            summarization_length, 
                            claude_model, 
                            risk_words
                        )
                        api_status_placeholder.empty()
                        
                        if result:
                            save_result(result)
                            st.session_state.result = result
                            st.session_state.selected_result = None
                            st.success("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†ï¼")
                    except Exception as e:
                        st.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    finally:
                        st.session_state.processing = False

    if st.session_state.get('result'):
        display_result(st.session_state.result)

    if "saved_results" in st.session_state and st.session_state.saved_results:
        st.sidebar.subheader("éå»ã®è©•ä¾¡çµæœ")
        for i, saved_result in enumerate(reversed(st.session_state.saved_results)):
            if st.sidebar.button(f"{saved_result['talent_name']} - {saved_result['timestamp']}", key=f"history_{i}"):
                st.session_state.selected_result = saved_result
                st.session_state.result = None

    if st.session_state.selected_result:
        st.subheader(f"éå»ã®è©•ä¾¡çµæœ: {st.session_state.selected_result['talent_name']}")
        st.write(st.session_state.selected_result['risk_report'])
        
        st.subheader("ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰åˆ¥è¦ç´„")
        for risk_word, summaries in st.session_state.selected_result['risk_summaries'].items():
            with st.expander(f"{risk_word}"):
                st.write("\n".join(summaries))
        
        st.subheader("å‚ç…§è¨˜äº‹ä¸€è¦§")
        for article in st.session_state.selected_result['articles']:
            if 'risk_score' in article:
                st.write(f"[{article['index']}] {article['title']} - {article['url']} (Risk: {article['risk_word']}, Score: {article['risk_score']:.2f})")
            else:
                st.write(f"[{article['index']}] {article['title']} - {article['url']} (Risk: {article['risk_word']}, Score: N/A)")

def main() -> None:
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼šStreamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨å®Ÿè¡Œ
    """
    st.set_page_config(layout="wide", page_title="ã‚¿ãƒ¬ãƒ³ãƒˆç‚ä¸Šãƒªã‚¹ã‚¯è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ", page_icon="ğŸ”¥")
    asyncio.run(main_async())

if __name__ == "__main__":
    main()