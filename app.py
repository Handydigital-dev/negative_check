import streamlit as st
import asyncio
import aiohttp
import time
import random
from fake_useragent import UserAgent
from bs4 import BeautifulSoup
import os
from dotenv import load_dotenv
import pandas as pd
import plotly.graph_objs as go
from textblob import TextBlob
import json
from datetime import datetime
import altair as alt
import re
from collections import Counter
import nltk
nltk.download('punkt')

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# å®šæ•°ã®å®šç¾©
API_ENDPOINTS = {
    "CLAUDE": "https://api.anthropic.com/v1/messages",
}
RETRY_ATTEMPTS = 5
MAX_CONCURRENT_REQUESTS = 3
BASE_DELAY = 2
MAX_RETRIES = 15
MAX_BACKOFF_DELAY = 60

TAVILY_API_KEY = os.environ.get("TAVILY_API_KEY")
CLAUDE_API_KEY = os.environ.get("CLAUDE_API_KEY")

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ï¼‰
KEYWORDS = {
    "æ”¿æ²»çš„æ€æƒ³ãƒ»ç™ºè¨€": ["æ”¿æ²»", "ç™ºè¨€", "æ‰¹åˆ¤", "è«–äº‰", "æŠ—è­°", "ãƒ‡ãƒ¢", "é¸æŒ™", "å…š", "ã‚¤ãƒ‡ã‚ªãƒ­ã‚®ãƒ¼"],
    "å•é¡Œãƒ»äº‹ä»¶ãƒ»äº‹æ•…ãƒ»è„±ç¨": ["é€®æ•", "äº‹ä»¶", "äº‹æ•…", "è„±ç¨", "é•æ³•", "çŠ¯ç½ª", "æ‘˜ç™º", "èª¿æŸ»", "ç–‘æƒ‘"],
    "è–¬ç‰©ãƒ»è£ç¤¾ä¼šãƒ»æš´åŠ›": ["è–¬ç‰©", "éº»è–¬", "æš´åŠ›", "æš´è¡Œ", "é•æ³•", "é€®æ•", "çµ„ç¹”", "çŠ¯ç½ª", "äº‹ä»¶"],
    "æ€§è”‘è¦–ãƒ»ã‚¸ã‚§ãƒ³ãƒ€ãƒ¼ãƒ»LGBT": ["å·®åˆ¥", "è”‘è¦–", "ã‚»ã‚¯ãƒãƒ©", "ãƒãƒ©ã‚¹ãƒ¡ãƒ³ãƒˆ", "æ‰¹åˆ¤", "æŠ—è­°", "è«–äº‰", "LGBT"],
    "ç†±æ„›ãƒ»ä¸å€«": ["ä¸å€«", "æµ®æ°—", "ã‚¹ã‚­ãƒ£ãƒ³ãƒ€ãƒ«", "é›¢å©š", "ç ´å±€", "ç†±æ„›", "äº¤éš›", "æ‹æ„›"],
    "ç‚ä¸Š": ["ç‚ä¸Š", "æ‰¹åˆ¤", "è¬ç½ª", "æ‰¹åˆ¤", "æ‰¹åˆ¤æ®ºåˆ°", "éé›£", "ãƒãƒƒã‚·ãƒ³ã‚°", "å•é¡Œç™ºè¨€"],
    "å®—æ•™": ["å®—æ•™", "ã‚«ãƒ«ãƒˆ", "ä¿¡è€…", "å¸ƒæ•™", "è«–äº‰", "æ‰¹åˆ¤", "å•é¡Œ"],
    "ãƒŒãƒ¼ãƒ‰": ["ãƒŒãƒ¼ãƒ‰", "å†™çœŸé›†", "éæ¿€", "ã‚»ã‚¯ã‚·ãƒ¼", "éœ²å‡º", "æ‰¹åˆ¤", "å•é¡Œ"]
}

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'processing' not in st.session_state:
    st.session_state.processing = False

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
def calculate_risk_score(text):
    blob = TextBlob(text)
    sentiment = blob.sentiment.polarity
    subjectivity = blob.sentiment.subjectivity
    
    # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚’ -1 (æœ€ã‚‚ãƒã‚¬ãƒ†ã‚£ãƒ–) ã‹ã‚‰ 1 (æœ€ã‚‚ãƒã‚¸ãƒ†ã‚£ãƒ–) ã®ã‚¹ã‚±ãƒ¼ãƒ«ã§å–å¾—
    # ã“ã‚Œã‚’ 0 ã‹ã‚‰ 100 ã®ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›ã—ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ãªæ–¹ãŒãƒªã‚¹ã‚¯ãŒé«˜ã„ã¨ã™ã‚‹
    sentiment_score = (1 - sentiment) * 50
    
    # ä¸»è¦³æ€§ã‚‚è€ƒæ…®ã™ã‚‹ã€‚ä¸»è¦³æ€§ãŒé«˜ã„ã»ã©ãƒªã‚¹ã‚¯ãŒé«˜ã„ã¨ä»®å®š
    subjectivity_score = subjectivity * 50
    
    # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã¨ä¸»è¦³æ€§ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã‚’ç®—å‡º
    risk_score = (sentiment_score + subjectivity_score) / 2
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    print(f"Text: {text[:100]}...")  # ãƒ†ã‚­ã‚¹ãƒˆã®æœ€åˆã®100æ–‡å­—ã‚’è¡¨ç¤º
    print(f"Sentiment: {sentiment}, Subjectivity: {subjectivity}")
    print(f"Calculated Risk Score: {risk_score}")
    
    return risk_score

async def get_webpage_content(session, url):
    try:
        ua = UserAgent()
        headers = {'User-Agent': ua.random}
        async with session.get(url, headers=headers, timeout=10) as response:
            response.raise_for_status()
            html = await response.text()
            return strip_html_tags(html)
    except aiohttp.ClientError as e:
        st.error(f"Error fetching webpage: {e}")
        return ""

def strip_html_tags(html):
    soup = BeautifulSoup(html, "html.parser")
    return soup.get_text()

async def call_claude_api_with_advanced_backoff(session, url, payload, headers):
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
    
    async def api_call():
        async with semaphore:
            for attempt in range(MAX_RETRIES):
                try:
                    async with session.post(url, json=payload, headers=headers) as response:
                        if response.status in [429, 529]:  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯éè² è·ã‚¨ãƒ©ãƒ¼
                            delay = min(BASE_DELAY * (2 ** attempt) + random.uniform(0, 1), MAX_BACKOFF_DELAY)
                            st.warning(f"API overloaded or rate limited. Retrying in {delay:.2f} seconds...")
                            await asyncio.sleep(delay)
                            continue
                        response.raise_for_status()
                        return await response.json()
                except aiohttp.ClientResponseError as e:
                    if e.status == 529:
                        delay = min(BASE_DELAY * (2 ** attempt) + random.uniform(0, 1), MAX_BACKOFF_DELAY)
                        st.warning(f"API overloaded. Retrying in {delay:.2f} seconds...")
                        await asyncio.sleep(delay)
                    elif attempt == MAX_RETRIES - 1:
                        raise
                    else:
                        delay = min(BASE_DELAY * (2 ** attempt) + random.uniform(0, 1), MAX_BACKOFF_DELAY)
                        st.warning(f"API call failed. Retrying in {delay:.2f} seconds... Error: {e}")
                        await asyncio.sleep(delay)
                except aiohttp.ClientError as e:
                    if attempt == MAX_RETRIES - 1:
                        raise
                    delay = min(BASE_DELAY * (2 ** attempt) + random.uniform(0, 1), MAX_BACKOFF_DELAY)
                    st.warning(f"API call failed. Retrying in {delay:.2f} seconds... Error: {e}")
                    await asyncio.sleep(delay)
        raise Exception("Max retries reached")

    return await api_call()

async def collect_risk_info(session, talent_name, risk_word, max_results, api_key):
    url = "https://api.tavily.com/search"
    query = f"{talent_name} {risk_word}"
    payload = {
        "api_key": api_key,
        "query": query,
        "search_depth": "advanced",
        "include_answer": True,
        "include_images": False,
        "include_raw_content": False,
        "max_results": max_results,
        "include_domains": [],
        "exclude_domains": []
    }
    try:
        async with session.post(url, json=payload) as response:
            response.raise_for_status()
            return await response.json()
    except aiohttp.ClientError as e:
        st.error(f"Error with Tavily API: {e}")
        return None
    
def calculate_advanced_risk_score(text, risk_category):
    blob = TextBlob(text)
    sentiment = blob.sentiment.polarity
    subjectivity = blob.sentiment.subjectivity

    word_counts = Counter(word for word in text.lower().split() if word in KEYWORDS[risk_category])
    keyword_score = sum(word_counts.values()) * 10

    numbers = re.findall(r'\d+', text)
    number_score = sum(int(num) for num in numbers if int(num) > 10) * 0.5

    context_phrases = [
        "è¬ç½ª", "æ‰¹åˆ¤", "å•é¡Œ", "ç‚ä¸Š", "é€®æ•", "ç–‘æƒ‘", "ã‚¹ã‚­ãƒ£ãƒ³ãƒ€ãƒ«", 
        "é™æ¿", "å¥‘ç´„è§£é™¤", "å¼•é€€", "æ´»å‹•ä¼‘æ­¢", "è¬¹æ…"
    ]
    context_score = sum(10 for phrase in context_phrases if phrase in text)

    complexity_score = len(text.split()) * 0.1
    sentiment_score = (1 - sentiment) * 25
    subjectivity_score = subjectivity * 25

    total_score = (
        keyword_score + 
        number_score + 
        context_score + 
        complexity_score + 
        sentiment_score + 
        subjectivity_score
    )

    normalized_score = min(100, max(0, total_score))

    return normalized_score, {
        "keyword_score": keyword_score,
        "number_score": number_score,
        "context_score": context_score,
        "complexity_score": complexity_score,
        "sentiment_score": sentiment_score,
        "subjectivity_score": subjectivity_score
    }


async def summarize_risk_content(session, content, risk_word, max_length, model, api_key):
    url = API_ENDPOINTS["CLAUDE"]
    prompt = f"ä»¥ä¸‹ã®æ–‡ç« ã‹ã‚‰{risk_word}ã«é–¢é€£ã™ã‚‹å†…å®¹ã‚’{max_length}æ–‡å­—ç¨‹åº¦ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚ç‰¹ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ãªå†…å®¹ã‚„æ½œåœ¨çš„ãªãƒªã‚¹ã‚¯ã«æ³¨ç›®ã—ã¦ãã ã•ã„ã€‚é–¢é€£ã™ã‚‹å†…å®¹ãŒãªã„å ´åˆã¯ã€Œé–¢é€£æƒ…å ±ãªã—ã€ã¨è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚\n\n{content}"
    payload = {
        "model": model,
        "max_tokens": min(max_length, 4096),
        "temperature": 0.7,
        "messages": [
            {"role": "user", "content": prompt}
        ],
    }
    headers = {
        "Content-Type": "application/json",
        "X-API-Key": api_key,
        "anthropic-version": "2023-06-01"
    }
    
    try:
        response_data = await call_claude_api_with_advanced_backoff(session, url, payload, headers)
        if 'content' in response_data:
            return response_data['content'][0]['text']
        else:
            st.error(f"Unexpected response format: {response_data}")
            return ""
    except Exception as e:
        st.error(f"Failed to summarize content: {e}")
        return ""

async def generate_risk_report(session, talent_name, risk_summaries, model, api_key, articles):
    url = API_ENDPOINTS["CLAUDE"]
    summaries_text = "\n\n".join([f"{word}:\n{summary}" for word, summary in risk_summaries.items()])
    articles_info = "\n".join([f"[{a['index']}] {a['title']} - {a['url']} (Risk: {a['risk_word']})" for a in articles])
    prompt = f"""ä»¥ä¸‹ã¯{talent_name}ã«é–¢ã™ã‚‹å„ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰ã®è¦ç´„ã§ã™ã€‚ã“ã‚Œã‚‰ã®æƒ…å ±ã‚’åŸºã«ã€{talent_name}ã®ç‚ä¸Šãƒªã‚¹ã‚¯ã‚’è©•ä¾¡ã—ã€300æ–‡å­—ç¨‹åº¦ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒ¬ãƒãƒ¼ãƒˆã«ã¯å…¨ä½“çš„ãªãƒªã‚¹ã‚¯è©•ä¾¡ã¨ã€ç‰¹ã«æ³¨æ„ã™ã¹ãç‚¹ã‚’å«ã‚ã¦ãã ã•ã„ã€‚ã¾ãŸã€é‡è¦ãªæƒ…å ±ã®å‡ºå…¸ã¨ã—ã¦ã€é©åˆ‡ãªè¨˜äº‹ç•ªå·ï¼ˆ[index]ã®å½¢å¼ï¼‰ã‚’æ‹¬å¼§æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚

è¦ç´„:
{summaries_text}

è¨˜äº‹ä¸€è¦§:
{articles_info}
"""
    
    payload = {
        "model": model,
        "max_tokens": 4096,
        "temperature": 0.7,
        "messages": [
            {"role": "user", "content": prompt}
        ],
    }
    headers = {
        "Content-Type": "application/json",
        "X-API-Key": api_key,
        "anthropic-version": "2023-06-01"
    }
    
    try:
        response_data = await call_claude_api_with_advanced_backoff(session, url, payload, headers)
        if 'content' in response_data:
            return response_data['content'][0]['text']
        else:
            st.error(f"Unexpected response format: {response_data}")
            return ""
    except Exception as e:
        st.error(f"Failed to generate risk report: {e}")
        return ""

async def process_talent_risks(session, TAVILY_API_KEY, CLAUDE_API_KEY, talent_name, max_results, summarization_length, claude_model, risk_words):
    risk_summaries = {}
    all_articles = []
    article_counter = 1

    progress_bar = st.progress(0)
    status_text = st.empty()

    for i, risk_word in enumerate(risk_words):
        status_text.text(f"Analyzing risk: {risk_word}")
        risk_info = await collect_risk_info(session, talent_name, risk_word, max_results, TAVILY_API_KEY)
        if risk_info:
            for j, result in enumerate(risk_info["results"][:max_results]):
                article = {
                    "index": article_counter,
                    "title": result["title"],
                    "url": result["url"],
                    "risk_word": risk_word
                }
                all_articles.append(article)
                article_counter += 1

                status_text.text(f"Processing article {article['index']}: {article['title']}")
                webpage_content = await get_webpage_content(session, article["url"])
                if webpage_content:
                    summary = await summarize_risk_content(session, webpage_content, risk_word, summarization_length, claude_model, CLAUDE_API_KEY)
                    if summary:
                        article["summary"] = summary
                        article["risk_score"], article["score_details"] = calculate_advanced_risk_score(summary, risk_word)
                        if risk_word not in risk_summaries:
                            risk_summaries[risk_word] = []
                        risk_summaries[risk_word].append(f"[{article['index']}] {summary} (Risk Score: {article['risk_score']:.2f})")
                    else:
                        st.warning(f"Failed to summarize article {article['index']}")
                else:
                    st.warning(f"Failed to fetch content for article {article['index']}")

        progress_bar.progress((i + 1) / len(risk_words))

    status_text.text("Generating final report...")
    risk_report = await generate_risk_report(session, talent_name, risk_summaries, claude_model, CLAUDE_API_KEY, all_articles)
    
    return {
        "talent_name": talent_name,
        "risk_summaries": risk_summaries,
        "risk_report": risk_report,
        "articles": all_articles
    }

def save_result(result):
    if "saved_results" not in st.session_state:
        st.session_state.saved_results = []
    st.session_state.saved_results.append({
        "timestamp": datetime.now().isoformat(),
        "talent_name": result["talent_name"],
        "risk_report": result["risk_report"],
        "articles": result["articles"]
    })

def display_risk_visualization(result):
    st.subheader("ç‚ä¸Šãƒªã‚¹ã‚¯å¯è¦–åŒ–")

    # å¹³å‡ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ã¨ã‚²ãƒ¼ã‚¸ãƒãƒ£ãƒ¼ãƒˆã®è¡¨ç¤º
    risk_scores = [article['risk_score'] for article in result['articles'] if 'risk_score' in article]
    if risk_scores:
        avg_risk_score = sum(risk_scores) / len(risk_scores)
        fig = go.Figure(go.Indicator(
            mode = "gauge+number",
            value = avg_risk_score,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "å¹³å‡ç‚ä¸Šãƒªã‚¹ã‚¯åº¦"},
            gauge = {
                'axis': {'range': [0, 100]},
                'bar': {'color': "darkred"},
                'steps' : [
                    {'range': [0, 33], 'color': "green"},
                    {'range': [33, 66], 'color': "yellow"},
                    {'range': [66, 100], 'color': "red"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': avg_risk_score
                }
            }
        ))
        st.plotly_chart(fig)
    
    # ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰åˆ¥ã®æ£’ã‚°ãƒ©ãƒ•
    risk_word_scores = {}
    for article in result['articles']:
        if 'risk_score' in article:
            if article['risk_word'] not in risk_word_scores:
                risk_word_scores[article['risk_word']] = []
            risk_word_scores[article['risk_word']].append(article['risk_score'])
    
    if risk_word_scores:
        avg_risk_word_scores = {word: sum(scores) / len(scores) for word, scores in risk_word_scores.items()}
        chart_data = pd.DataFrame({
            'ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰': list(avg_risk_word_scores.keys()),
            'ã‚¹ã‚³ã‚¢': list(avg_risk_word_scores.values())
        })
        
        st.write("ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰åˆ¥å¹³å‡ã‚¹ã‚³ã‚¢:")
        st.write(chart_data)
        
        chart = alt.Chart(chart_data).mark_bar().encode(
            x='ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰',
            y='ã‚¹ã‚³ã‚¢',
            color=alt.Color('ã‚¹ã‚³ã‚¢:Q', scale=alt.Scale(domain=[0, 33, 66, 100], range=['green', 'yellow', 'orange', 'red']))
        ).properties(
            title='ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰åˆ¥å¹³å‡ã‚¹ã‚³ã‚¢'
        )
        
        st.altair_chart(chart, use_container_width=True)

    # ã‚¹ã‚³ã‚¢è©³ç´°ã®è¡¨ç¤º
    st.subheader("ã‚¹ã‚³ã‚¢è©³ç´°")
    for article in result['articles']:
        if 'score_details' in article:
            st.write(f"Article {article['index']} - {article['title']}:")
            st.write(f"Total Risk Score: {article['risk_score']:.2f}")
            st.write("Score Breakdown:")
            for key, value in article['score_details'].items():
                st.write(f"  {key}: {value:.2f}")
            st.write("---")                

async def main_async():
    st.title("ğŸ”¥ ã‚¿ãƒ¬ãƒ³ãƒˆç‚ä¸Šãƒªã‚¹ã‚¯è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")
    st.text("è¨­å®šã®ã‚¿ãƒ¬ãƒ³ãƒˆåã«åå‰ã‚’å…¥åŠ›ã—ã¦ã€Œãƒ¬ãƒãƒ¼ãƒˆä½œæˆã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™")
    st.sidebar.title("è¨­å®š")

    talent_name = st.sidebar.text_input("ã‚¿ãƒ¬ãƒ³ãƒˆå", key="talent_name")
    max_results = st.sidebar.slider("ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰ã”ã¨ã®å–å¾—è¨˜äº‹æ•°", 1, 10, 5, key="max_results")
    summarization_length = st.sidebar.slider("è¦ç´„ã™ã‚‹éš›ã®æ–‡å­—æ•°", 100, 500, 200, key="summarization_length")
    claude_model = st.sidebar.selectbox("ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", ["claude-3-opus-20240229", "claude-3-haiku-20240307","claude-3-5-sonnet-20240620"], index=1, key="claude_model")

    default_risk_words = "æ”¿æ²»çš„æ€æƒ³ãƒ»ç™ºè¨€\nå•é¡Œãƒ»äº‹ä»¶ãƒ»äº‹æ•…ãƒ»è„±ç¨\nè–¬ç‰©ãƒ»è£ç¤¾ä¼šãƒ»æš´åŠ›\næ€§è”‘è¦–ãƒ»ã‚¸ã‚§ãƒ³ãƒ€ãƒ¼ãƒ»LGBT\nç†±æ„›ãƒ»ä¸å€«\nç‚ä¸Š\nå®—æ•™\nãƒŒãƒ¼ãƒ‰"
    risk_words_input = st.sidebar.text_area("ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰ (1è¡Œã«1ã¤)", value=default_risk_words, height=200, key="risk_words")
    risk_words = [word.strip() for word in risk_words_input.split('\n') if word.strip()]

    if st.sidebar.button("ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"):
        if not TAVILY_API_KEY:
            st.error("Tavily API key is required.")
        elif not talent_name.strip():
            st.error("ã‚¿ãƒ¬ãƒ³ãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif not CLAUDE_API_KEY:
            st.error("Claude API key is required.")
        elif not risk_words:
            st.error("å°‘ãªãã¨ã‚‚1ã¤ã®ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.session_state.processing = True
            async with aiohttp.ClientSession() as session:
                with st.spinner("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­..."):
                    result = await process_talent_risks(
                        session, 
                        TAVILY_API_KEY, 
                        CLAUDE_API_KEY, 
                        talent_name, 
                        max_results, 
                        summarization_length, 
                        claude_model, 
                        risk_words
                    )
                    
                    if result:
                        save_result(result)
                        st.success("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†ï¼")
                        
                        st.subheader("ç·åˆãƒªã‚¹ã‚¯è©•ä¾¡")
                        st.write(result['risk_report'])
                        
                        display_risk_visualization(result)
                        
                        st.subheader("ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰åˆ¥è¦ç´„")
                        for risk_word, summaries in result['risk_summaries'].items():
                            with st.expander(f"{risk_word}"):
                                st.write("\n".join(summaries))
                        
                        st.subheader("å‚ç…§è¨˜äº‹ä¸€è¦§")
                        for article in result['articles']:
                            if 'risk_score' in article:
                                st.write(f"[{article['index']}] {article['title']} - {article['url']} (Risk: {article['risk_word']}, Score: {article['risk_score']:.2f})")
                            else:
                                st.write(f"[{article['index']}] {article['title']} - {article['url']} (Risk: {article['risk_word']}, Score: N/A)")
                        
                        # ãƒ¬ãƒãƒ¼ãƒˆã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
                        report_json = json.dumps(result, ensure_ascii=False, indent=2)
                        st.download_button(
                            label="ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=report_json,
                            file_name=f"{talent_name}_risk_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json"
                        )
            st.session_state.processing = False

    if "saved_results" in st.session_state and st.session_state.saved_results:
        st.sidebar.subheader("éå»ã®è©•ä¾¡çµæœ")
        for i, saved_result in enumerate(reversed(st.session_state.saved_results)):
            if st.sidebar.button(f"{saved_result['talent_name']} - {saved_result['timestamp']}", key=f"history_{i}"):
                st.subheader(f"éå»ã®è©•ä¾¡çµæœ: {saved_result['talent_name']}")
                st.write(saved_result['risk_report'])
                st.write("å‚ç…§è¨˜äº‹:")
                for article in saved_result['articles']:
                    if 'risk_score' in article:
                        st.write(f"[{article['index']}] {article['title']} (Risk Score: {article['risk_score']:.2f})")
                    else:
                        st.write(f"[{article['index']}] {article['title']} (Risk Score: N/A)")

def main():
    st.set_page_config(layout="wide", page_title="ã‚¿ãƒ¬ãƒ³ãƒˆç‚ä¸Šãƒªã‚¹ã‚¯è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ", page_icon="ğŸ”¥")
    asyncio.run(main_async())

if __name__ == "__main__":
    main()